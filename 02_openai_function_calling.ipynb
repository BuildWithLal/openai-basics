{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07acc2df-ddd4-454b-9948-a64daae25235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d348afd7-7ad2-4826-b223-d4ad41d72fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "270e9202-1a37-4c02-9322-03cb87b4e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ddba9af-a9e7-4284-a3b8-20e106588884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e924d03-c05b-415b-9d58-d6e6f2185cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e77412-b39a-489f-9045-5993d6236ed6",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31856b99-33a0-4988-9db9-2f03cb5248fe",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "connect large language models to external tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdaca05-668e-4580-aa6d-aa0f551ad69a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3061a39-fe9a-403f-9643-9521db8834bf",
   "metadata": {},
   "source": [
    "### Trying to get real-time data using Chat API Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5714424-d40c-4bf1-ad74-20bd618f9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am sorry, I do not have real-time information. It is recommended to check a local weather website or app for the most up-to-date weather information in London.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0f69-cecb-4ec3-976e-0847e168f535",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38ec2a-1623-49ba-a103-982a748dc9f2",
   "metadata": {},
   "source": [
    "### Get real-time data using function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19bdac51-6010-4c4c-9a81-deb6c939d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city, e.g., San Francisco, London\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "              \"description\": \"The temperature unit to use. use the correct unit here based on the user's location.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "      }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9e7e-20c3-4776-8859-085203537690",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f608dcc-c261-471e-980c-5a8e58a65998",
   "metadata": {},
   "source": [
    "### Chat model auto decides whether to use a function call or get and return output response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "702a758e-d191-4a9d-9273-8e10a3ec64ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Euro Cup 2024 has not taken place yet, as of my last update in December 2023. The UEFA European Championship is typically held every four years, and the 2024 tournament is scheduled to be hosted by Germany.', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the Euro Cup 2024?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7f708-2788-454f-8d64-b1c0a7734081",
   "metadata": {},
   "source": [
    "##### No text response from chat model but intead returning to call a function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab23b-6619-4121-864b-3c5212bfb892",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92a1699b-4f4a-4be5-af2e-44438de6d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uH663UcbtIdnIJ6krtVt4lM8', function=Function(arguments='{\"location\":\"Berlin\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"required\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the last FIFA football?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6fe99-54a4-4062-accf-b708c5e0919e",
   "metadata": {},
   "source": [
    "#### ^ Based on function, model auto detects the correct unit to be used.\n",
    "London: Celsius, New York: Fahrenheit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084c0e1-8c84-46d4-9954-8e4bfde67591",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe12edf4-2f12-494c-84ac-82ebd379ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The national football team with the most FIFA World Cup wins is Brazil. They have won the FIFA World Cup a record 5 times: in 1958, 1962, 1970, 1994, and 2002.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",  # auto is default\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Which team the most FIFA World Cup wins\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88260346-c7e4-418d-b61e-8d8fb86d2fd7",
   "metadata": {},
   "source": [
    "##### Model auto decided to not suggest a function call as it has the answer for query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28233fbf-55d3-4e4c-a3e7-48638f771ec6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71b6a2-97fd-42e6-a6c6-950fb3a08298",
   "metadata": {},
   "source": [
    "### Force model to use function call instead of output response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2b02457-5ac9-4fbc-8b5e-9d530fde4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_APwIXE5qXDMvS2LH38KXzmug', function=Function(arguments='{\"location\":\"an\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"required\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Which team the most FIFA World Cup wins\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dbc44-c8ad-46e4-963f-2d6d14d37bde",
   "metadata": {},
   "source": [
    "##### Even the model had a response for the query, but still suggested to call function as it was forced by the chat arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d3755-1356-466e-bec6-dfa2f37941c6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21647c68-d60c-42e4-b287-e09d02446493",
   "metadata": {},
   "source": [
    "##### Example dummy function to return the weather. This could be your backend API or an external API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e0f724c-4cdc-42c7-93be-639de99f6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"new york\" in location.lower():\n",
    "        return json.dumps({\"location\": \"New York\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"london\" in location.lower():\n",
    "        return json.dumps({\"location\": \"London\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd19ff-d38f-4a71-a3b9-d0dcdd24b6d3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df9def-7411-45fc-9f93-eb3074bd9a32",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c626e-3ab7-4a89-9e3c-ea0002f9a83b",
   "metadata": {},
   "source": [
    "### All in a single place to test function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c33debd1-f7a7-4fbc-aaa3-6ea36181386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wlNSNn004RlENBLJ3XDvLesF', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]) \n",
      "\n",
      "\n",
      "[{'role': 'user', 'content': 'What is the weather like today in London?'}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wlNSNn004RlENBLJ3XDvLesF', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_wlNSNn004RlENBLJ3XDvLesF', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"London\", \"temperature\": \"22\", \"unit\": \"Celsius\"}'}] \n",
      "\n",
      "\n",
      "The weather in London today is 22 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message, '\\n\\n')\n",
    "\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "# check if the model wanted to call a function\n",
    "\n",
    "if tool_calls:\n",
    "    # the JSON response may not always be valid; be sure to handle errors\n",
    "    \n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }\n",
    "    \n",
    "    # only one function in this example, but you can have multiple\n",
    "    \n",
    "    messages.append(response.choices[0].message)  # extend conversation with assistant's reply\n",
    "    \n",
    "    # send the info for each function call and function response to the model\n",
    "    tool_call = tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "    # extend conversation with function response\n",
    "\n",
    "    print(messages, '\\n\\n')\n",
    "    \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    # get a new response from the model where it can see the function response\n",
    "    \n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a296a6-6543-47a0-90bf-debf2d0aaa32",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b38ec-7594-4d51-84be-2ca718f35df9",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b775f-e98c-4014-8ba6-94c763290675",
   "metadata": {},
   "source": [
    "### Make function calling re-usable by moving to a generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96c38cdb-9444-4625-93ce-adbb2fbd0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_live_weather_update(messages, response, function):\n",
    "    print(\"Initial Response: \", '\\n\\n')\n",
    "    pprint.pp(response.choices[0].message, indent=4)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    if not tool_calls:\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    available_functions = {\n",
    "        function.__name__: function,\n",
    "    }\n",
    "\n",
    "    # extend conversation with assistant's reply\n",
    "    messages.append(response.choices[0].message)\n",
    "    \n",
    "    # send the info for each function call and function response to the model\n",
    "    tool_call = tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "\n",
    "    print(\"Response from our weather API: \", '\\n\\n')\n",
    "    pprint.pp(function_response, indent=4)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # appending new message to existing messages for sending back to chat model\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Messages going to model: \", '\\n\\n')\n",
    "    pprint.pp(messages, indent=4, depth=2)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(\"Final response from model: \", '\\n\\n')\n",
    "    pprint.pp(response.choices[0].message, indent=4, depth=2)\n",
    "\n",
    "    # re-send messages to chat model to generate output based on actual function call\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60bac6dd-4a4d-48f5-bdc5-dddf52364008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lEHOnIffbDTOAFJY9bPUjxXF', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])\n",
      "\n",
      "\n",
      "\n",
      "Response from our weather API:  \n",
      "\n",
      "\n",
      "'{\"location\": \"London\", \"temperature\": \"22\", \"unit\": \"Celsius\"}'\n",
      "\n",
      "\n",
      "\n",
      "Messages going to model:  \n",
      "\n",
      "\n",
      "[   {'role': 'user', 'content': 'What was the weather like today in London?'},\n",
      "    ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lEHOnIffbDTOAFJY9bPUjxXF', function=Function(arguments='{\"location\":\"London\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]),\n",
      "    {   'tool_call_id': 'call_lEHOnIffbDTOAFJY9bPUjxXF',\n",
      "        'role': 'tool',\n",
      "        'name': 'get_current_weather',\n",
      "        'content': '{\"location\": \"London\", \"temperature\": \"22\", \"unit\": '\n",
      "                   '\"Celsius\"}'}]\n",
      "\n",
      "\n",
      "\n",
      "Final response from model:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The weather in London today was 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in London today was 22 degrees Celsius.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the weather like today in London?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f54f6d9-4fd4-462c-9741-92156673e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3WWkvLc6qEeFKypw0TFZY00N', function=Function(arguments='{\"location\":\"New York\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')])\n",
      "\n",
      "\n",
      "\n",
      "Response from our weather API:  \n",
      "\n",
      "\n",
      "'{\"location\": \"New York\", \"temperature\": \"72\", \"unit\": \"Celsius\"}'\n",
      "\n",
      "\n",
      "\n",
      "Messages going to model:  \n",
      "\n",
      "\n",
      "[   {'role': 'user', 'content': 'What was the weather like today in New York?'},\n",
      "    ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3WWkvLc6qEeFKypw0TFZY00N', function=Function(arguments='{\"location\":\"New York\",\"unit\":\"Celsius\"}', name='get_current_weather'), type='function')]),\n",
      "    {   'tool_call_id': 'call_3WWkvLc6qEeFKypw0TFZY00N',\n",
      "        'role': 'tool',\n",
      "        'name': 'get_current_weather',\n",
      "        'content': '{\"location\": \"New York\", \"temperature\": \"72\", \"unit\": '\n",
      "                   '\"Celsius\"}'}]\n",
      "\n",
      "\n",
      "\n",
      "Final response from model:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The weather in New York today was 72 degrees Celsius.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in New York today was 72 degrees Celsius.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the weather like today in New York?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20b9f8f6-0813-4e50-89e2-177196905b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response:  \n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='The first president of the United States was George Washington.', role='assistant', function_call=None, tool_calls=None)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first president of the United States was George Washington.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who was the first president of US?\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=50,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "get_live_weather_update(messages, response, get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01fc31-99d5-4d78-a545-84c2dbf54017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
